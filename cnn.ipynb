{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils import OneHotEncoder\n",
    "from dataset import Dataset\n",
    "from cnn import Cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Cnn()\n",
    "dataset = Dataset('mnist')\n",
    "encoder = OneHotEncoder(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-batch 1 loss: 74.07913260100764\n",
      "Mini-batch 2 loss: 53.791350089514495\n",
      "Mini-batch 3 loss: 92.2556368137345\n",
      "Mini-batch 4 loss: 95.444912797615\n",
      "Mini-batch 5 loss: 69.6610793942799\n",
      "Mini-batch 6 loss: 106.28413119717148\n",
      "Mini-batch 7 loss: 74.24889504296765\n",
      "Mini-batch 8 loss: 79.52333051968887\n",
      "Mini-batch 9 loss: 98.98672527757529\n",
      "Mini-batch 10 loss: 67.8938952531602\n",
      "Mini-batch 11 loss: 74.63766803508655\n",
      "Mini-batch 12 loss: 44.354773259591994\n",
      "num_correct: 8\n",
      "Mini-batch 13 loss: 73.4586613846723\n",
      "Mini-batch 14 loss: 46.129212432998926\n",
      "Mini-batch 15 loss: 20.935803694405333\n",
      "Mini-batch 16 loss: 29.601162914913\n",
      "Mini-batch 17 loss: 16.172793107173973\n",
      "Mini-batch 18 loss: 18.877904216657267\n",
      "Mini-batch 19 loss: 26.274139470670463\n",
      "Mini-batch 20 loss: 30.617511410556617\n",
      "Mini-batch 21 loss: 46.75647318254763\n",
      "Mini-batch 22 loss: 21.348574621719656\n",
      "Mini-batch 23 loss: 26.28781907877886\n",
      "Mini-batch 24 loss: 23.31197842772204\n",
      "Mini-batch 25 loss: 25.265653817591545\n",
      "num_correct: 6\n",
      "Mini-batch 26 loss: 30.246004060763312\n",
      "Mini-batch 27 loss: 18.910715369493005\n",
      "Mini-batch 28 loss: 29.364927703260364\n",
      "Mini-batch 29 loss: 32.332656237958666\n",
      "Mini-batch 30 loss: 30.0545370059903\n",
      "Mini-batch 31 loss: 23.722709953716937\n",
      "Mini-batch 32 loss: 13.554547907315627\n",
      "Mini-batch 33 loss: 14.013230682190994\n",
      "Mini-batch 34 loss: 25.644447809255542\n",
      "Mini-batch 35 loss: 11.067207669212365\n",
      "Mini-batch 36 loss: 14.876012752629132\n",
      "Mini-batch 37 loss: 15.8372914193427\n",
      "num_correct: 12\n",
      "Mini-batch 38 loss: 10.661094173240851\n",
      "Mini-batch 39 loss: 19.12635979119869\n",
      "Mini-batch 40 loss: 11.140988406341831\n",
      "Mini-batch 41 loss: 15.2829629379305\n",
      "Mini-batch 42 loss: 15.976617730063039\n",
      "Mini-batch 43 loss: 14.325941906631924\n",
      "Mini-batch 44 loss: 20.98707977110761\n",
      "Mini-batch 45 loss: 14.5025404801003\n",
      "Mini-batch 46 loss: 20.965216201358892\n",
      "Mini-batch 47 loss: 16.19421554367499\n",
      "Mini-batch 48 loss: 23.120269069707344\n",
      "Mini-batch 49 loss: 19.987590137821186\n",
      "Mini-batch 50 loss: 10.689224459735344\n",
      "num_correct: 17\n",
      "Mini-batch 51 loss: 22.066545846748493\n",
      "Mini-batch 52 loss: 14.641031165289746\n",
      "Mini-batch 53 loss: 8.654683064731449\n",
      "Mini-batch 54 loss: 10.818721183248703\n",
      "Mini-batch 55 loss: 11.44894041049419\n",
      "Mini-batch 56 loss: 11.604509515140357\n",
      "Mini-batch 57 loss: 7.455204128917516\n",
      "Mini-batch 58 loss: 13.047770878752358\n",
      "Mini-batch 59 loss: 25.121082349030814\n",
      "Mini-batch 60 loss: 11.93728170521965\n",
      "Mini-batch 61 loss: 6.157185696720278\n",
      "Mini-batch 62 loss: 11.322679128409938\n",
      "num_correct: 13\n",
      "Mini-batch 63 loss: 11.771336313159093\n",
      "Mini-batch 64 loss: 9.710776124046053\n",
      "Mini-batch 65 loss: 10.010693333357214\n",
      "Mini-batch 66 loss: 22.37056792300722\n",
      "Mini-batch 67 loss: 12.032535451440708\n",
      "Mini-batch 68 loss: 7.061760076021263\n",
      "Mini-batch 69 loss: 9.266292644813209\n",
      "Mini-batch 70 loss: 13.211900055400656\n",
      "Mini-batch 71 loss: 17.451016079484134\n",
      "Mini-batch 72 loss: 17.452673813472156\n",
      "Mini-batch 73 loss: 14.837660367653244\n",
      "Mini-batch 74 loss: 7.595556875268075\n",
      "Mini-batch 75 loss: 5.887680022429073\n",
      "num_correct: 20\n",
      "Mini-batch 76 loss: 13.424466765730354\n",
      "Mini-batch 77 loss: 8.438681227877675\n",
      "Mini-batch 78 loss: 6.586682018847463\n",
      "Mini-batch 79 loss: 5.653160981136932\n",
      "Mini-batch 80 loss: 7.743781890137157\n",
      "Mini-batch 81 loss: 5.551586561837085\n",
      "Mini-batch 82 loss: 8.98609099255231\n",
      "Mini-batch 83 loss: 6.745153859881855\n",
      "Mini-batch 84 loss: 8.170252809710249\n",
      "Mini-batch 85 loss: 13.719253027247536\n",
      "Mini-batch 86 loss: 4.934959143651172\n",
      "Mini-batch 87 loss: 11.494602467783583\n",
      "num_correct: 20\n",
      "Mini-batch 88 loss: 5.540989194762039\n",
      "Mini-batch 89 loss: 4.816798509244423\n",
      "Mini-batch 90 loss: 7.184437074543933\n",
      "Mini-batch 91 loss: 12.081280198625528\n",
      "Mini-batch 92 loss: 5.889530989579489\n",
      "Mini-batch 93 loss: 9.823444998367027\n",
      "Mini-batch 94 loss: 12.428073822974525\n",
      "Mini-batch 95 loss: 11.696646146551076\n",
      "Mini-batch 96 loss: 17.926079810372723\n",
      "Mini-batch 97 loss: 9.30558851294956\n",
      "Mini-batch 98 loss: 6.8336190215373325\n",
      "Mini-batch 99 loss: 8.615917422790222\n",
      "Mini-batch 100 loss: 12.362148777787876\n",
      "num_correct: 20\n",
      "Mini-batch 101 loss: 11.440489392947685\n",
      "Mini-batch 102 loss: 10.409309744759074\n",
      "Mini-batch 103 loss: 12.781255465868078\n",
      "Mini-batch 104 loss: 16.72549834449611\n",
      "Mini-batch 105 loss: 12.116308622667848\n",
      "Mini-batch 106 loss: 9.662809166664093\n",
      "Mini-batch 107 loss: 6.987425803238996\n",
      "Mini-batch 108 loss: 7.058754521561523\n",
      "Mini-batch 109 loss: 9.89307805858071\n",
      "Mini-batch 110 loss: 4.655614743994873\n",
      "Mini-batch 111 loss: 12.829101595676658\n",
      "Mini-batch 112 loss: 10.460809173210357\n",
      "num_correct: 17\n",
      "Mini-batch 113 loss: 11.831294488013922\n",
      "Mini-batch 114 loss: 4.702229000656405\n",
      "Mini-batch 115 loss: 8.441562719921697\n",
      "Mini-batch 116 loss: 6.112093373935259\n",
      "Mini-batch 117 loss: 9.532004757253082\n",
      "Mini-batch 118 loss: 5.706721041315535\n",
      "Mini-batch 119 loss: 2.4840150308259927\n",
      "Mini-batch 120 loss: 10.913279227712998\n",
      "Mini-batch 121 loss: 8.86215984961192\n",
      "Mini-batch 122 loss: 6.705240812738245\n",
      "Mini-batch 123 loss: 13.757910967502863\n",
      "Mini-batch 124 loss: 4.117339898872022\n",
      "Mini-batch 125 loss: 6.817564932878781\n",
      "num_correct: 23\n",
      "Saving state after 1000 iterations. Completed 12% of test set\n",
      "Mini-batch 126 loss: 3.117173644713667\n",
      "Mini-batch 127 loss: 3.226981677193368\n",
      "Mini-batch 128 loss: 9.485638419666495\n",
      "Mini-batch 129 loss: 5.454381991730497\n",
      "Mini-batch 130 loss: 15.22475446696278\n",
      "Mini-batch 131 loss: 2.625913453904012\n",
      "Mini-batch 132 loss: 7.088526718757299\n",
      "Mini-batch 133 loss: 3.9852112403430695\n",
      "Mini-batch 134 loss: 8.196087132566463\n",
      "Mini-batch 135 loss: 6.421587119033699\n",
      "Mini-batch 136 loss: 12.169914222035557\n",
      "Mini-batch 137 loss: 7.7266465957981945\n",
      "num_correct: 22\n",
      "Mini-batch 138 loss: 4.827120310424057\n",
      "Mini-batch 139 loss: 14.842177706974878\n",
      "Mini-batch 140 loss: 2.741782845859298\n",
      "Mini-batch 141 loss: 3.210189526474446\n",
      "Mini-batch 142 loss: 4.4408234757486404\n",
      "Mini-batch 143 loss: 4.323309651475183\n",
      "Mini-batch 144 loss: 7.5144732744555025\n",
      "Mini-batch 145 loss: 5.759499088103042\n",
      "Mini-batch 146 loss: 12.347688958642514\n",
      "Mini-batch 147 loss: 3.254374257063276\n",
      "Mini-batch 148 loss: 6.405100371581988\n",
      "Mini-batch 149 loss: 3.275380955541012\n",
      "Mini-batch 150 loss: 6.284238693177869\n",
      "num_correct: 21\n",
      "Mini-batch 151 loss: 1.073470710373756\n",
      "Mini-batch 152 loss: 3.4555919381975033\n",
      "Mini-batch 153 loss: 3.376729138828377\n",
      "Mini-batch 154 loss: 7.625270935093435\n",
      "Mini-batch 155 loss: 5.968374458138712\n",
      "Mini-batch 156 loss: 3.755153940026557\n",
      "Mini-batch 157 loss: 5.650067312619756\n",
      "Mini-batch 158 loss: 1.9508875423666718\n",
      "Mini-batch 159 loss: 2.5208175698274116\n",
      "Mini-batch 160 loss: 5.031312398088281\n",
      "Mini-batch 161 loss: 7.515367434586724\n",
      "Mini-batch 162 loss: 7.226791490466052\n",
      "num_correct: 22\n",
      "Mini-batch 163 loss: 0.8659553220970742\n",
      "Mini-batch 164 loss: 7.858580142618275\n",
      "Mini-batch 165 loss: 5.0991873828598\n",
      "Mini-batch 166 loss: 0.7360926188359109\n",
      "Mini-batch 167 loss: 7.501191340756825\n",
      "Mini-batch 168 loss: 7.836071442292821\n",
      "Mini-batch 169 loss: 2.6912475107982923\n",
      "Mini-batch 170 loss: 5.574439813246355\n",
      "Mini-batch 171 loss: 6.036805930436996\n",
      "Mini-batch 172 loss: 8.467696402310041\n",
      "Mini-batch 173 loss: 6.3665772256353765\n",
      "Mini-batch 174 loss: 0.9109559555884594\n",
      "Mini-batch 175 loss: 5.059760394046788\n",
      "num_correct: 25\n",
      "Mini-batch 176 loss: 7.728738043110356\n",
      "Mini-batch 177 loss: 4.437943172683693\n",
      "Mini-batch 178 loss: 3.741268631755414\n",
      "Mini-batch 179 loss: 5.0693559572566596\n",
      "Mini-batch 180 loss: 6.294355910747181\n",
      "Mini-batch 181 loss: 3.496071096236335\n",
      "Mini-batch 182 loss: 4.9569470838798155\n",
      "Mini-batch 183 loss: 1.0518440765350106\n",
      "Mini-batch 184 loss: 11.92266110429287\n",
      "Mini-batch 185 loss: 2.8735793613813176\n",
      "Mini-batch 186 loss: 8.60842096161868\n",
      "Mini-batch 187 loss: 0.8217517920240474\n",
      "num_correct: 23\n",
      "Mini-batch 188 loss: 6.905399606823693\n",
      "Mini-batch 189 loss: 2.2061256540859095\n",
      "Mini-batch 190 loss: 4.110668167833104\n",
      "Mini-batch 191 loss: 5.08277196678759\n",
      "Mini-batch 192 loss: 4.396601965600891\n",
      "Mini-batch 193 loss: 2.202852343240635\n",
      "Mini-batch 194 loss: 6.904020110998531\n",
      "Mini-batch 195 loss: 5.382072485802748\n",
      "Mini-batch 196 loss: 7.06039023191455\n",
      "Mini-batch 197 loss: 2.5737922599493865\n",
      "Mini-batch 198 loss: 2.6108168818721245\n",
      "Mini-batch 199 loss: 4.073604293704633\n",
      "Mini-batch 200 loss: 3.3203145465455495\n",
      "num_correct: 23\n",
      "Mini-batch 201 loss: 4.083388634204219\n",
      "Mini-batch 202 loss: 2.3685705733412097\n",
      "Mini-batch 203 loss: 5.437602258450879\n",
      "Mini-batch 204 loss: 5.046511908903564\n",
      "Mini-batch 205 loss: 2.8142333385378326\n",
      "Mini-batch 206 loss: 1.9338495404116873\n",
      "Mini-batch 207 loss: 6.3378651677824775\n",
      "Mini-batch 208 loss: 3.5077949059219775\n",
      "Mini-batch 209 loss: 9.099179221097573\n",
      "Mini-batch 210 loss: 3.103318283308665\n",
      "Mini-batch 211 loss: 3.6733660350383563\n",
      "Mini-batch 212 loss: 8.176115272070387\n",
      "num_correct: 21\n",
      "Mini-batch 213 loss: 8.550761600216557\n",
      "Mini-batch 214 loss: 3.404795900237967\n",
      "Mini-batch 215 loss: 14.736248522287267\n",
      "Mini-batch 216 loss: 2.998154306579495\n",
      "Mini-batch 217 loss: 12.637297441962849\n",
      "Mini-batch 218 loss: 4.2720730333403045\n",
      "Mini-batch 219 loss: 3.9287599809592146\n",
      "Mini-batch 220 loss: 8.652842265806802\n",
      "Mini-batch 221 loss: 8.162959436811478\n",
      "Mini-batch 222 loss: 3.2619111073975975\n",
      "Mini-batch 223 loss: 10.041586051135225\n",
      "Mini-batch 224 loss: 2.2033902007213837\n",
      "Mini-batch 225 loss: 8.031267978716564\n",
      "num_correct: 22\n",
      "Mini-batch 226 loss: 1.8566735947890352\n",
      "Mini-batch 227 loss: 7.721715513386209\n",
      "Mini-batch 228 loss: 0.5396539837171385\n",
      "Mini-batch 229 loss: 8.139104962608217\n",
      "Mini-batch 230 loss: 9.015090621369861\n",
      "Mini-batch 231 loss: 13.58319612682983\n",
      "Mini-batch 232 loss: 1.3656204865039583\n",
      "Mini-batch 233 loss: 1.7910542045619031\n",
      "Mini-batch 234 loss: 2.7941598441520674\n",
      "Mini-batch 235 loss: 6.688759666296803\n",
      "Mini-batch 236 loss: 12.235662010443267\n",
      "Mini-batch 237 loss: 6.239016479450652\n",
      "num_correct: 21\n",
      "Mini-batch 238 loss: 4.639890412618636\n",
      "Mini-batch 239 loss: 11.923432824523625\n",
      "Mini-batch 240 loss: 4.5044154359705555\n",
      "Mini-batch 241 loss: 4.945615019993446\n",
      "Mini-batch 242 loss: 5.669496260210356\n",
      "Mini-batch 243 loss: 1.6801723742288566\n",
      "Mini-batch 244 loss: 0.6670013066819421\n",
      "Mini-batch 245 loss: 1.120976625408887\n",
      "Mini-batch 246 loss: 3.8309055163446795\n",
      "Mini-batch 247 loss: 9.850426075507034\n",
      "Mini-batch 248 loss: 2.833545837836801\n",
      "Mini-batch 249 loss: 5.02529058912343\n",
      "Mini-batch 250 loss: 5.321156070258766\n",
      "num_correct: 25\n",
      "Saving state after 2000 iterations. Completed 25% of test set\n",
      "Mini-batch 251 loss: 6.245269887150063\n",
      "Mini-batch 252 loss: 7.092165566202979\n",
      "Mini-batch 253 loss: 2.425216617658849\n",
      "Mini-batch 254 loss: 3.49618393856893\n",
      "Mini-batch 255 loss: 1.8491565485010844\n",
      "Mini-batch 256 loss: 3.1298461318812723\n",
      "Mini-batch 257 loss: 3.307845653622551\n",
      "Mini-batch 258 loss: 5.212000391483936\n",
      "Mini-batch 259 loss: 8.85593385031763\n",
      "Mini-batch 260 loss: 11.08369560527158\n",
      "Mini-batch 261 loss: 3.161947905575041\n",
      "Mini-batch 262 loss: 2.9821941160330048\n",
      "num_correct: 25\n",
      "Mini-batch 263 loss: 3.5269627420071057\n",
      "Mini-batch 264 loss: 6.067976584545988\n",
      "Mini-batch 265 loss: 7.807027131678398\n",
      "Mini-batch 266 loss: 3.7065825937158325\n",
      "Mini-batch 267 loss: 5.659656454963017\n",
      "Mini-batch 268 loss: 1.7667436974409252\n",
      "Mini-batch 269 loss: 2.077353902831086\n",
      "Mini-batch 270 loss: 3.2345850566182173\n",
      "Mini-batch 271 loss: 8.150875543965768\n",
      "Mini-batch 272 loss: 6.3507980250606675\n",
      "Mini-batch 273 loss: 5.12646780391538\n",
      "Mini-batch 274 loss: 3.25465184185582\n",
      "Mini-batch 275 loss: 14.795649916294407\n",
      "num_correct: 24\n",
      "Mini-batch 276 loss: 3.136818175569287\n",
      "Mini-batch 277 loss: 4.804983533583146\n",
      "Mini-batch 278 loss: 0.2253072680014785\n",
      "Mini-batch 279 loss: 2.9527938716616027\n",
      "Mini-batch 280 loss: 12.282940613736475\n",
      "Mini-batch 281 loss: 5.387125663606233\n",
      "Mini-batch 282 loss: 6.984096045266853\n",
      "Mini-batch 283 loss: 4.8983697632594865\n",
      "Mini-batch 284 loss: 9.080934423801448\n",
      "Mini-batch 285 loss: 3.5668160687295964\n",
      "Mini-batch 286 loss: 9.774897863390038\n",
      "Mini-batch 287 loss: 7.033284242492666\n",
      "num_correct: 25\n",
      "Mini-batch 288 loss: 2.567805076127164\n",
      "Mini-batch 289 loss: 9.30566456345607\n",
      "Mini-batch 290 loss: 8.113354522058538\n",
      "Mini-batch 291 loss: 4.373493020597151\n",
      "Mini-batch 292 loss: 6.084575659706035\n",
      "Mini-batch 293 loss: 10.9819233593824\n",
      "Mini-batch 294 loss: 4.26365509066801\n",
      "Mini-batch 295 loss: 5.507893051398665\n",
      "Mini-batch 296 loss: 1.6698559480569173\n",
      "Mini-batch 297 loss: 5.519640317183886\n",
      "Mini-batch 298 loss: 7.957771223161187\n",
      "Mini-batch 299 loss: 3.5209071209944547\n",
      "Mini-batch 300 loss: 7.806837486400893\n",
      "num_correct: 27\n",
      "Mini-batch 301 loss: 1.9286450383427118\n",
      "Mini-batch 302 loss: 2.6175661070677934\n",
      "Mini-batch 303 loss: 3.5616109523173733\n",
      "Mini-batch 304 loss: 4.293409420958401\n",
      "Mini-batch 305 loss: 7.374860093164175\n",
      "Mini-batch 306 loss: 6.39450514548237\n",
      "Mini-batch 307 loss: 0.30906666983766096\n",
      "Mini-batch 308 loss: 2.5290562818598934\n",
      "Mini-batch 309 loss: 2.013419884022324\n",
      "Mini-batch 310 loss: 1.256147625595947\n",
      "Mini-batch 311 loss: 5.75478237062137\n",
      "Mini-batch 312 loss: 1.0480762923277145\n",
      "num_correct: 21\n",
      "Mini-batch 313 loss: 1.5946662057072478\n",
      "Mini-batch 314 loss: 5.098619915867659\n",
      "Mini-batch 315 loss: 4.895464869131925\n",
      "Mini-batch 316 loss: 1.2190332675979088\n",
      "Mini-batch 317 loss: 7.31613572051751\n",
      "Mini-batch 318 loss: 8.094030695262393\n",
      "Mini-batch 319 loss: 4.5168010471384425\n",
      "Mini-batch 320 loss: 0.11130946499033562\n",
      "Mini-batch 321 loss: 2.1597323239951294\n",
      "Mini-batch 322 loss: 0.8065637621980946\n",
      "Mini-batch 323 loss: 7.821176712697179\n",
      "Mini-batch 324 loss: 7.039225614402812\n",
      "Mini-batch 325 loss: 5.279669056837056\n",
      "num_correct: 23\n",
      "Mini-batch 326 loss: 5.374435190985886\n",
      "Mini-batch 327 loss: 2.5842873832523225\n",
      "Mini-batch 328 loss: 1.800777703039485\n",
      "Mini-batch 329 loss: 2.3939142596094705\n",
      "Mini-batch 330 loss: 3.827106193390673\n",
      "Mini-batch 331 loss: 2.3630590487052974\n",
      "Mini-batch 332 loss: 3.982675679461605\n",
      "Mini-batch 333 loss: 3.932655887915844\n",
      "Mini-batch 334 loss: 2.7855040850319277\n",
      "Mini-batch 335 loss: 0.726792631469075\n",
      "Mini-batch 336 loss: 1.8771571453406461\n",
      "Mini-batch 337 loss: 0.9846022599685408\n",
      "num_correct: 28\n",
      "Mini-batch 338 loss: 2.3105122213707836\n",
      "Mini-batch 339 loss: 0.2495509516701183\n",
      "Mini-batch 340 loss: 9.582435391952592\n",
      "Mini-batch 341 loss: 11.08674106284597\n",
      "Mini-batch 342 loss: 6.484089026619251\n",
      "Mini-batch 343 loss: 6.239521813797451\n",
      "Mini-batch 344 loss: 6.86293388726501\n",
      "Mini-batch 345 loss: 7.994641394521586\n",
      "Mini-batch 346 loss: 1.4160137784872755\n",
      "Mini-batch 347 loss: 1.018719779240513\n",
      "Mini-batch 348 loss: 2.5957373034174895\n",
      "Mini-batch 349 loss: 3.826963090214432\n",
      "Mini-batch 350 loss: 8.424139461352034\n",
      "num_correct: 24\n",
      "Mini-batch 351 loss: 1.5817814202693539\n",
      "Mini-batch 352 loss: 7.612934765968368\n",
      "Mini-batch 353 loss: 10.33732671331748\n",
      "Mini-batch 354 loss: 10.285064100291484\n",
      "Mini-batch 355 loss: 2.3425833413148105\n",
      "Mini-batch 356 loss: 7.823521827317292\n",
      "Mini-batch 357 loss: 1.6955870714210435\n",
      "Mini-batch 358 loss: 2.2510528140218287\n",
      "Mini-batch 359 loss: 1.3443818855156562\n",
      "Mini-batch 360 loss: 1.678090032742343\n",
      "Mini-batch 361 loss: 7.629806636283465\n",
      "Mini-batch 362 loss: 1.1747303325926042\n",
      "num_correct: 25\n",
      "Mini-batch 363 loss: 6.098298444633393\n",
      "Mini-batch 364 loss: 6.468795519949101\n",
      "Mini-batch 365 loss: 0.8558611593773462\n",
      "Mini-batch 366 loss: 1.1224516804402171\n",
      "Mini-batch 367 loss: 4.1047682121652755\n",
      "Mini-batch 368 loss: 7.711424565400106\n",
      "Mini-batch 369 loss: 3.5056983130936086\n",
      "Mini-batch 370 loss: 3.1042615953809465\n",
      "Mini-batch 371 loss: 8.106566413982796\n",
      "Mini-batch 372 loss: 2.7092548807278267\n",
      "Mini-batch 373 loss: 0.9892232543892427\n",
      "Mini-batch 374 loss: 7.87263307515912\n",
      "Mini-batch 375 loss: 1.677230223605263\n",
      "num_correct: 26\n",
      "Saving state after 3000 iterations. Completed 38% of test set\n",
      "Mini-batch 376 loss: 0.197610152052295\n",
      "Mini-batch 377 loss: 1.4028400014271183\n",
      "Mini-batch 378 loss: 2.422683641522223\n",
      "Mini-batch 379 loss: 3.9799525886321145\n",
      "Mini-batch 380 loss: 1.4643141324243696\n",
      "Mini-batch 381 loss: 2.3582788770893472\n",
      "Mini-batch 382 loss: 3.7228844454728973\n",
      "Mini-batch 383 loss: 2.7586754731147267\n",
      "Mini-batch 384 loss: 0.9492066133324856\n",
      "Mini-batch 385 loss: 5.6012966476679455\n",
      "Mini-batch 386 loss: 4.793215141715635\n",
      "Mini-batch 387 loss: 0.49234317864238386\n",
      "num_correct: 24\n",
      "Mini-batch 388 loss: 4.379691861080493\n",
      "Mini-batch 389 loss: 4.0049444960862814\n",
      "Mini-batch 390 loss: 2.554843594088622\n",
      "Mini-batch 391 loss: 1.8408012909917233\n",
      "Mini-batch 392 loss: 2.3051367995144583\n",
      "Mini-batch 393 loss: 5.559366260583852\n",
      "Mini-batch 394 loss: 2.48465077313634\n",
      "Mini-batch 395 loss: 8.268582971177636\n",
      "Mini-batch 396 loss: 3.9795961881803277\n",
      "Mini-batch 397 loss: 3.7031945139209546\n",
      "Mini-batch 398 loss: 0.8256951543394209\n",
      "Mini-batch 399 loss: 4.556970623711052\n",
      "Mini-batch 400 loss: 2.972800263279754\n",
      "num_correct: 25\n",
      "Mini-batch 401 loss: 3.0931504383757282\n",
      "Mini-batch 402 loss: 8.507295222759645\n",
      "Mini-batch 403 loss: 2.0729757067010928\n",
      "Mini-batch 404 loss: 0.8850184029778676\n",
      "Mini-batch 405 loss: 5.043997007312356\n",
      "Mini-batch 406 loss: 2.9860611949064624\n",
      "Mini-batch 407 loss: 6.794011362205458\n",
      "Mini-batch 408 loss: 2.8924963211999786\n",
      "Mini-batch 409 loss: 1.0378255862604462\n",
      "Mini-batch 410 loss: 7.135649382827726\n",
      "Mini-batch 411 loss: 3.851507861083679\n",
      "Mini-batch 412 loss: 1.097398255118493\n",
      "num_correct: 27\n",
      "Mini-batch 413 loss: 1.2064516943264942\n",
      "Mini-batch 414 loss: 0.3149572218778069\n",
      "Mini-batch 415 loss: 0.14985256328223864\n",
      "Mini-batch 416 loss: 0.6758544164188465\n",
      "Mini-batch 417 loss: 2.3144866794522736\n",
      "Mini-batch 418 loss: 1.9537269910087331\n",
      "Mini-batch 419 loss: 1.1584089484755629\n",
      "Mini-batch 420 loss: 2.1548716274864974\n",
      "Mini-batch 421 loss: 4.968954282207247\n",
      "Mini-batch 422 loss: 3.4122000931927845\n",
      "Mini-batch 423 loss: 3.2941195966603787\n",
      "Mini-batch 424 loss: 0.41376540471547363\n",
      "Mini-batch 425 loss: 2.806210771137492\n",
      "num_correct: 24\n",
      "Mini-batch 426 loss: 2.155772633722601\n",
      "Mini-batch 427 loss: 1.9795251423775937\n",
      "Mini-batch 428 loss: 4.238273815132835\n",
      "Mini-batch 429 loss: 4.033081401235229\n",
      "Mini-batch 430 loss: 2.9082294840332326\n",
      "Mini-batch 431 loss: 5.284930369579948\n",
      "Mini-batch 432 loss: 6.362622939957008\n",
      "Mini-batch 433 loss: 2.588610422205653\n",
      "Mini-batch 434 loss: 1.62464848319846\n",
      "Mini-batch 435 loss: 4.9308965979978385\n",
      "Mini-batch 436 loss: 1.8379404602924283\n",
      "Mini-batch 437 loss: 0.9936002027387892\n",
      "num_correct: 27\n",
      "Mini-batch 438 loss: 8.24775787382711\n",
      "Mini-batch 439 loss: 10.09584814461753\n",
      "Mini-batch 440 loss: 5.5465268559399545\n",
      "Mini-batch 441 loss: 0.8622427280243858\n",
      "Mini-batch 442 loss: 0.9243242216444917\n",
      "Mini-batch 443 loss: 0.9747424936833942\n",
      "Mini-batch 444 loss: 3.525100127476374\n",
      "Mini-batch 445 loss: 2.3330766508300287\n",
      "Mini-batch 446 loss: 1.7056759181178454\n",
      "Mini-batch 447 loss: 4.228639216102795\n",
      "Mini-batch 448 loss: 0.3446284615449123\n",
      "Mini-batch 449 loss: 0.780188702379905\n",
      "Mini-batch 450 loss: 7.761283996860419\n",
      "num_correct: 24\n",
      "Mini-batch 451 loss: 3.1994957229032703\n",
      "Mini-batch 452 loss: 0.898389588758994\n",
      "Mini-batch 453 loss: 4.240246626715171\n",
      "Mini-batch 454 loss: 0.22625583435037475\n",
      "Mini-batch 455 loss: 2.7134006904595043\n",
      "Mini-batch 456 loss: 6.319722127704237\n",
      "Mini-batch 457 loss: 0.5548121719972103\n",
      "Mini-batch 458 loss: 1.4609682133877748\n",
      "Mini-batch 459 loss: 5.3780723658824\n",
      "Mini-batch 460 loss: 1.3187396329463943\n",
      "Mini-batch 461 loss: 2.576842002464362\n",
      "Mini-batch 462 loss: 1.7406598460036964\n",
      "num_correct: 25\n",
      "Mini-batch 463 loss: 1.953009929756896\n",
      "Mini-batch 464 loss: 6.5611041180106655\n",
      "Mini-batch 465 loss: 3.8482927101974997\n",
      "Mini-batch 466 loss: 6.438987069091737\n",
      "Mini-batch 467 loss: 4.368755414509397\n",
      "Mini-batch 468 loss: 2.3991625619123664\n",
      "Mini-batch 469 loss: 5.600257075358503\n",
      "Mini-batch 470 loss: 4.649191445192251\n",
      "Mini-batch 471 loss: 2.741994723884148\n",
      "Mini-batch 472 loss: 6.701036138126132\n",
      "Mini-batch 473 loss: 1.873389980583765\n",
      "Mini-batch 474 loss: 0.38402924342574174\n",
      "Mini-batch 475 loss: 0.1322943276020035\n",
      "num_correct: 23\n",
      "Mini-batch 476 loss: 6.837499092522289\n",
      "Mini-batch 477 loss: 6.978237710605827\n",
      "Mini-batch 478 loss: 4.237346845307645\n",
      "Mini-batch 479 loss: 0.7144135071518317\n",
      "Mini-batch 480 loss: 3.2914597382450967\n",
      "Mini-batch 481 loss: 6.064046358270907\n",
      "Mini-batch 482 loss: 4.308011393634381\n",
      "Mini-batch 483 loss: 1.7913668668696316\n",
      "Mini-batch 484 loss: 1.3266686757180266\n",
      "Mini-batch 485 loss: 1.2757617543574518\n",
      "Mini-batch 486 loss: 6.80654133254763\n",
      "Mini-batch 487 loss: 5.83310111461109\n",
      "num_correct: 24\n",
      "Mini-batch 488 loss: 2.149230322074634\n",
      "Mini-batch 489 loss: 8.72231269008992\n",
      "Mini-batch 490 loss: 2.806182641167017\n",
      "Mini-batch 491 loss: 0.7601207485415657\n",
      "Mini-batch 492 loss: 2.0275558774587283\n",
      "Mini-batch 493 loss: 0.5150219865199788\n",
      "Mini-batch 494 loss: 3.183716018709041\n",
      "Mini-batch 495 loss: 3.9343948845352026\n",
      "Mini-batch 496 loss: 3.3400155219246828\n",
      "Mini-batch 497 loss: 2.9103998651134866\n",
      "Mini-batch 498 loss: 0.23002510037980312\n",
      "Mini-batch 499 loss: 2.5677785386773153\n",
      "Mini-batch 500 loss: 3.7068843851463953\n",
      "num_correct: 23\n",
      "Saving state after 4000 iterations. Completed 50% of test set\n",
      "Mini-batch 501 loss: 7.768997258187286\n",
      "Mini-batch 502 loss: 5.20981690703607\n",
      "Mini-batch 503 loss: 1.7765635951957008\n",
      "Mini-batch 504 loss: 5.810408882826816\n",
      "Mini-batch 505 loss: 3.782087403238579\n",
      "Mini-batch 506 loss: 0.36277571908698447\n",
      "Mini-batch 507 loss: 12.378022228266346\n",
      "Mini-batch 508 loss: 3.524771710073047\n",
      "Mini-batch 509 loss: 1.7542134785840595\n",
      "Mini-batch 510 loss: 4.005976182835494\n",
      "Mini-batch 511 loss: 5.75780075644366\n",
      "Mini-batch 512 loss: 6.325731093142438\n",
      "num_correct: 23\n",
      "Mini-batch 513 loss: 1.5355688717618312\n",
      "Mini-batch 514 loss: 4.16472142479861\n",
      "Mini-batch 515 loss: 1.3551544626580423\n",
      "Mini-batch 516 loss: 0.7004225377862843\n",
      "Mini-batch 517 loss: 0.6205299709100239\n",
      "Mini-batch 518 loss: 1.5826076906491886\n",
      "Mini-batch 519 loss: 6.395026440147685\n",
      "Mini-batch 520 loss: 2.9031116312023855\n",
      "Mini-batch 521 loss: 2.335817769330051\n",
      "Mini-batch 522 loss: 0.754613924502647\n",
      "Mini-batch 523 loss: 0.807392837097196\n",
      "Mini-batch 524 loss: 2.8893914785508206\n",
      "Mini-batch 525 loss: 3.133042572581281\n",
      "num_correct: 26\n",
      "Mini-batch 526 loss: 0.8402708837192734\n",
      "Mini-batch 527 loss: 2.4405784849542993\n",
      "Mini-batch 528 loss: 6.601343391898269\n",
      "Mini-batch 529 loss: 2.5602398598624787\n",
      "Mini-batch 530 loss: 1.238508282467669\n",
      "Mini-batch 531 loss: 1.9633563337889408\n",
      "Mini-batch 532 loss: 0.24298886705334416\n",
      "Mini-batch 533 loss: 3.3348777104667384\n",
      "Mini-batch 534 loss: 1.2887797626801707\n",
      "Mini-batch 535 loss: 1.6980239532723267\n",
      "Mini-batch 536 loss: 1.267603923843987\n",
      "Mini-batch 537 loss: 1.597336170260434\n",
      "num_correct: 27\n",
      "Mini-batch 538 loss: 0.7744851651929371\n",
      "Mini-batch 539 loss: 4.147291340050281\n",
      "Mini-batch 540 loss: 1.7433277702680767\n",
      "Mini-batch 541 loss: 2.1973639710128143\n",
      "Mini-batch 542 loss: 2.1134279731141596\n",
      "Mini-batch 543 loss: 1.3488892162674804\n",
      "Mini-batch 544 loss: 7.056427014148543\n",
      "Mini-batch 545 loss: 9.076069627998326\n",
      "Mini-batch 546 loss: 3.4539807752232847\n",
      "Mini-batch 547 loss: 0.8209351997972255\n",
      "Mini-batch 548 loss: 1.5709490743931531\n",
      "Mini-batch 549 loss: 1.423022963546944\n",
      "Mini-batch 550 loss: 9.163792157744929\n",
      "num_correct: 26\n",
      "Mini-batch 551 loss: 5.6446718856172\n",
      "Mini-batch 552 loss: 0.9132298829995864\n",
      "Mini-batch 553 loss: 6.123652819716654\n",
      "Mini-batch 554 loss: 12.02058555269576\n",
      "Mini-batch 555 loss: 3.2407468577385967\n",
      "Mini-batch 556 loss: 10.763272379043197\n",
      "Mini-batch 557 loss: 0.4991538043547785\n",
      "Mini-batch 558 loss: 4.2246134092290655\n",
      "Mini-batch 559 loss: 2.231574189305605\n",
      "Mini-batch 560 loss: 0.49914762644508626\n",
      "Mini-batch 561 loss: 3.232843625329389\n",
      "Mini-batch 562 loss: 5.379959214879051\n",
      "num_correct: 27\n",
      "Mini-batch 563 loss: 0.952170317620277\n",
      "Mini-batch 564 loss: 2.0016503748453887\n",
      "Mini-batch 565 loss: 0.9140288963704124\n",
      "Mini-batch 566 loss: 0.7142886420578934\n",
      "Mini-batch 567 loss: 3.276043341548299\n",
      "Mini-batch 568 loss: 1.5366531139044466\n",
      "Mini-batch 569 loss: 4.4609882455756065\n",
      "Mini-batch 570 loss: 9.02516156370842\n",
      "Mini-batch 571 loss: 5.440753614052038\n",
      "Mini-batch 572 loss: 1.9451260773257792\n",
      "Mini-batch 573 loss: 7.229594243533051\n",
      "Mini-batch 574 loss: 0.7727571634360284\n",
      "Mini-batch 575 loss: 0.8485985092292612\n",
      "num_correct: 27\n",
      "Mini-batch 576 loss: 5.571654032827404\n",
      "Mini-batch 577 loss: 8.09621474483938\n",
      "Mini-batch 578 loss: 3.7493833315244616\n",
      "Mini-batch 579 loss: 0.4135652508366215\n",
      "Mini-batch 580 loss: 8.227626373583602\n",
      "Mini-batch 581 loss: 2.9163105925586197\n",
      "Mini-batch 582 loss: 1.068886853078932\n",
      "Mini-batch 583 loss: 1.3154135888872498\n",
      "Mini-batch 584 loss: 8.191965904287043\n",
      "Mini-batch 585 loss: 3.842370334846205\n",
      "Mini-batch 586 loss: 1.0826884776129928\n",
      "Mini-batch 587 loss: 0.332689592971085\n",
      "num_correct: 25\n",
      "Mini-batch 588 loss: 0.9227713788421208\n",
      "Mini-batch 589 loss: 10.08434488714612\n",
      "Mini-batch 590 loss: 7.2968912571463\n",
      "Mini-batch 591 loss: 10.414121852005518\n",
      "Mini-batch 592 loss: 1.6893796904907177\n",
      "Mini-batch 593 loss: 5.931817940288174\n",
      "Mini-batch 594 loss: 2.7271541426735038\n",
      "Mini-batch 595 loss: 7.4639881875001\n",
      "Mini-batch 596 loss: 0.3207790551230391\n",
      "Mini-batch 597 loss: 4.346013314742475\n",
      "Mini-batch 598 loss: 0.82244171903921\n",
      "Mini-batch 599 loss: 3.971440226389153\n",
      "Mini-batch 600 loss: 1.2386581373684578\n",
      "num_correct: 28\n",
      "Mini-batch 601 loss: 4.442406912057319\n",
      "Mini-batch 602 loss: 4.80397683024068\n",
      "Mini-batch 603 loss: 5.7750872757461\n",
      "Mini-batch 604 loss: 1.626700560111556\n",
      "Mini-batch 605 loss: 5.525118288139929\n",
      "Mini-batch 606 loss: 0.9600904309130593\n",
      "Mini-batch 607 loss: 7.416036399284866\n",
      "Mini-batch 608 loss: 1.1884580486160845\n",
      "Mini-batch 609 loss: 1.029030948004583\n",
      "Mini-batch 610 loss: 0.46938491499262974\n",
      "Mini-batch 611 loss: 4.733788619519891\n",
      "Mini-batch 612 loss: 5.183516440240952\n",
      "num_correct: 29\n",
      "Mini-batch 613 loss: 3.618417595654789\n",
      "Mini-batch 614 loss: 5.441258550942145\n",
      "Mini-batch 615 loss: 4.1634826524992885\n",
      "Mini-batch 616 loss: 3.1739477234202607\n",
      "Mini-batch 617 loss: 7.766695225248567\n",
      "Mini-batch 618 loss: 3.312639078919551\n",
      "Mini-batch 619 loss: 0.8950774773633186\n",
      "Mini-batch 620 loss: 0.6249528171504308\n",
      "Mini-batch 621 loss: 0.07089850415583335\n",
      "Mini-batch 622 loss: 0.39045717409895114\n",
      "Mini-batch 623 loss: 0.05341399490381551\n",
      "Mini-batch 624 loss: 2.1025788935826353\n",
      "Mini-batch 625 loss: 2.9240850189637806\n",
      "num_correct: 24\n",
      "Saving state after 5000 iterations. Completed 62% of test set\n",
      "Mini-batch 626 loss: 1.1915083237088175\n",
      "Mini-batch 627 loss: 3.228803932513381\n",
      "Mini-batch 628 loss: 1.0054549228500027\n",
      "Mini-batch 629 loss: 1.8047984908328747\n",
      "Mini-batch 630 loss: 2.2906260968219687\n",
      "Mini-batch 631 loss: 1.3005968756574777\n",
      "Mini-batch 632 loss: 8.150429097089294\n",
      "Mini-batch 633 loss: 9.485028554515344\n",
      "Mini-batch 634 loss: 0.5378483315234153\n",
      "Mini-batch 635 loss: 3.7562385674910224\n",
      "Mini-batch 636 loss: 3.2868264969747742\n",
      "Mini-batch 637 loss: 4.013749123772969\n",
      "num_correct: 25\n",
      "Mini-batch 638 loss: 11.503025436020613\n",
      "Mini-batch 639 loss: 0.7692250521477133\n",
      "Mini-batch 640 loss: 2.126080923688273\n",
      "Mini-batch 641 loss: 4.163074771090935\n",
      "Mini-batch 642 loss: 6.537588698709944\n",
      "Mini-batch 643 loss: 0.8058072395706637\n",
      "Mini-batch 644 loss: 4.088318847384824\n",
      "Mini-batch 645 loss: 0.6929948355163561\n",
      "Mini-batch 646 loss: 2.6246102704503653\n",
      "Mini-batch 647 loss: 4.693552864311095\n",
      "Mini-batch 648 loss: 0.16882041059124558\n",
      "Mini-batch 649 loss: 10.205147948872728\n",
      "Mini-batch 650 loss: 1.4037939359136613\n",
      "num_correct: 24\n",
      "Mini-batch 651 loss: 6.94112138816131\n",
      "Mini-batch 652 loss: 5.8421905212388365\n",
      "Mini-batch 653 loss: 2.7552774762152863\n",
      "Mini-batch 654 loss: 2.04629035884627\n",
      "Mini-batch 655 loss: 0.6938953119199779\n",
      "Mini-batch 656 loss: 4.366733514980498\n",
      "Mini-batch 657 loss: 0.4697213623434149\n",
      "Mini-batch 658 loss: 0.29752788629688426\n",
      "Mini-batch 659 loss: 0.6542595886178001\n",
      "Mini-batch 660 loss: 0.9266671774240236\n",
      "Mini-batch 661 loss: 1.1402899400591888\n",
      "Mini-batch 662 loss: 0.4942825732632512\n",
      "num_correct: 25\n",
      "Mini-batch 663 loss: 3.791850582255159\n",
      "Mini-batch 664 loss: 7.95080085701473\n",
      "Mini-batch 665 loss: 1.2312593892396297\n",
      "Mini-batch 666 loss: 2.192944629481209\n",
      "Mini-batch 667 loss: 2.023081378493098\n",
      "Mini-batch 668 loss: 2.279669074772177\n",
      "Mini-batch 669 loss: 3.299263018590436\n",
      "Mini-batch 670 loss: 8.610299021639296\n",
      "Mini-batch 671 loss: 0.15149618562404085\n",
      "Mini-batch 672 loss: 4.481863081330547\n",
      "Mini-batch 673 loss: 0.8210500852569497\n",
      "Mini-batch 674 loss: 3.012540737657411\n",
      "Mini-batch 675 loss: 13.913894147190293\n",
      "num_correct: 27\n",
      "Mini-batch 676 loss: 9.959466412412787\n",
      "Mini-batch 677 loss: 4.262449573709555\n",
      "Mini-batch 678 loss: 0.9402194617656268\n",
      "Mini-batch 679 loss: 0.23226133524368864\n",
      "Mini-batch 680 loss: 2.0783356505143757\n",
      "Mini-batch 681 loss: 2.7191737106114\n",
      "Mini-batch 682 loss: 4.253468088296704\n",
      "Mini-batch 683 loss: 0.3499441652173898\n",
      "Mini-batch 684 loss: 0.6307594588309756\n",
      "Mini-batch 685 loss: 3.147660483832108\n",
      "Mini-batch 686 loss: 0.9771341585882869\n",
      "Mini-batch 687 loss: 2.5994138845610437\n",
      "num_correct: 25\n",
      "Mini-batch 688 loss: 6.485402457697939\n",
      "Mini-batch 689 loss: 0.2920284327832339\n",
      "Mini-batch 690 loss: 3.315773656084464\n",
      "Mini-batch 691 loss: 3.841223108635071\n",
      "Mini-batch 692 loss: 6.002501253674317\n",
      "Mini-batch 693 loss: 7.664867554525524\n",
      "Mini-batch 694 loss: 0.3759148588578505\n",
      "Mini-batch 695 loss: 2.584191303368859\n",
      "Mini-batch 696 loss: 3.4690001518682556\n",
      "Mini-batch 697 loss: 1.92846123974144\n",
      "Mini-batch 698 loss: 2.888389914357776\n",
      "Mini-batch 699 loss: 1.4703764281796958\n",
      "Mini-batch 700 loss: 1.344959436537076\n",
      "num_correct: 27\n",
      "Mini-batch 701 loss: 3.646883747738484\n",
      "Mini-batch 702 loss: 0.2090306834076904\n",
      "Mini-batch 703 loss: 1.209092388275772\n",
      "Mini-batch 704 loss: 5.761242117668876\n",
      "Mini-batch 705 loss: 0.5086301603076686\n",
      "Mini-batch 706 loss: 3.4055810002705185\n",
      "Mini-batch 707 loss: 0.4342400768726165\n",
      "Mini-batch 708 loss: 0.4461750367496024\n",
      "Mini-batch 709 loss: 1.6830390803394046\n",
      "Mini-batch 710 loss: 6.202406978345891\n",
      "Mini-batch 711 loss: 6.500890341136993\n",
      "Mini-batch 712 loss: 4.038506543867764\n",
      "num_correct: 26\n",
      "Mini-batch 713 loss: 4.104905902188984\n",
      "Mini-batch 714 loss: 2.5572943588691333\n",
      "Mini-batch 715 loss: 0.6932833457690657\n",
      "Mini-batch 716 loss: 0.5473626890077191\n",
      "Mini-batch 717 loss: 4.956589623613619\n",
      "Mini-batch 718 loss: 4.420374417226502\n",
      "Mini-batch 719 loss: 9.660257612335899\n",
      "Mini-batch 720 loss: 0.6525880078126864\n",
      "Mini-batch 721 loss: 0.23870783650116476\n",
      "Mini-batch 722 loss: 1.0807748509779807\n",
      "Mini-batch 723 loss: 6.665118568290173\n",
      "Mini-batch 724 loss: 1.1035308375544104\n",
      "Mini-batch 725 loss: 2.56316803106303\n",
      "num_correct: 26\n",
      "Mini-batch 726 loss: 5.593952067169109\n",
      "Mini-batch 727 loss: 2.3274484413046976\n",
      "Mini-batch 728 loss: 0.5411806670856898\n",
      "Mini-batch 729 loss: 2.2105299183357188\n",
      "Mini-batch 730 loss: 5.0244827868928645\n",
      "Mini-batch 731 loss: 0.34399849858117415\n",
      "Mini-batch 732 loss: 0.8980010345581327\n",
      "Mini-batch 733 loss: 2.3445648571588302\n",
      "Mini-batch 734 loss: 10.13354551501357\n",
      "Mini-batch 735 loss: 0.6827645009053412\n",
      "Mini-batch 736 loss: 1.819599902563884\n",
      "Mini-batch 737 loss: 1.9146265633580721\n",
      "num_correct: 27\n",
      "Mini-batch 738 loss: 3.948995378084312\n",
      "Mini-batch 739 loss: 7.002558194092597\n",
      "Mini-batch 740 loss: 0.8283556341826598\n",
      "Mini-batch 741 loss: 0.8465865624711558\n",
      "Mini-batch 742 loss: 3.2206079566574695\n",
      "Mini-batch 743 loss: 0.34004861331529845\n",
      "Mini-batch 744 loss: 8.824660828127847\n",
      "Mini-batch 745 loss: 0.09689851239135797\n",
      "Mini-batch 746 loss: 1.850084841486252\n",
      "Mini-batch 747 loss: 11.869880147356383\n",
      "Mini-batch 748 loss: 5.227490464860323\n",
      "Mini-batch 749 loss: 12.179441033499899\n",
      "Mini-batch 750 loss: 8.781818250423884\n",
      "num_correct: 25\n",
      "Saving state after 6000 iterations. Completed 75% of test set\n",
      "Mini-batch 751 loss: 0.09419848896639811\n",
      "Mini-batch 752 loss: 3.656807006788616\n",
      "Mini-batch 753 loss: 0.6062208240039645\n",
      "Mini-batch 754 loss: 0.8686408813167473\n",
      "Mini-batch 755 loss: 8.673224740603718\n",
      "Mini-batch 756 loss: 0.8066168953352518\n",
      "Mini-batch 757 loss: 1.2440230287721412\n",
      "Mini-batch 758 loss: 0.52926744869954\n",
      "Mini-batch 759 loss: 2.033154527558758\n",
      "Mini-batch 760 loss: 1.1191919042709184\n",
      "Mini-batch 761 loss: 7.61999700593807\n",
      "Mini-batch 762 loss: 1.454440458149535\n",
      "num_correct: 25\n",
      "Mini-batch 763 loss: 1.383309274464169\n",
      "Mini-batch 764 loss: 2.8660085721040898\n",
      "Mini-batch 765 loss: 0.19466873973935983\n",
      "Mini-batch 766 loss: 1.1694493116077327\n",
      "Mini-batch 767 loss: 10.76879367370731\n",
      "Mini-batch 768 loss: 1.5283361408762792\n",
      "Mini-batch 769 loss: 8.176935265691641\n",
      "Mini-batch 770 loss: 12.2025430482618\n",
      "Mini-batch 771 loss: 4.080454406051971\n",
      "Mini-batch 772 loss: 0.9116221988575596\n",
      "Mini-batch 773 loss: 1.6242837490415063\n",
      "Mini-batch 774 loss: 6.749780423334134\n",
      "Mini-batch 775 loss: 3.578678592136437\n",
      "num_correct: 28\n",
      "Mini-batch 776 loss: 4.931149818836808\n",
      "Mini-batch 777 loss: 0.7033050531347637\n",
      "Mini-batch 778 loss: 4.586219202047756\n",
      "Mini-batch 779 loss: 0.6813825121979787\n",
      "Mini-batch 780 loss: 6.70006595362378\n",
      "Mini-batch 781 loss: 0.6876344917249285\n",
      "Mini-batch 782 loss: 0.4353571324127849\n",
      "Mini-batch 783 loss: 10.072248783552487\n",
      "Mini-batch 784 loss: 2.762136425833107\n",
      "Mini-batch 785 loss: 1.1369279559587573\n",
      "Mini-batch 786 loss: 5.561073069725264\n",
      "Mini-batch 787 loss: 1.2430272642194056\n",
      "num_correct: 25\n",
      "Mini-batch 788 loss: 2.885288007838879\n",
      "Mini-batch 789 loss: 5.248286556708552\n",
      "Mini-batch 790 loss: 4.784568360060317\n",
      "Mini-batch 791 loss: 0.9078746105116303\n",
      "Mini-batch 792 loss: 0.019415101299843678\n",
      "Mini-batch 793 loss: 2.9823585829877413\n",
      "Mini-batch 794 loss: 2.702161833788649\n",
      "Mini-batch 795 loss: 0.5277867331252115\n",
      "Mini-batch 796 loss: 1.2120572935520018\n",
      "Mini-batch 797 loss: 0.4392394058065682\n",
      "Mini-batch 798 loss: 2.0383971378778396\n",
      "Mini-batch 799 loss: 0.33564719097820234\n",
      "Mini-batch 800 loss: 1.4153929423419365\n",
      "num_correct: 27\n",
      "Mini-batch 801 loss: 0.4534574308756802\n",
      "Mini-batch 802 loss: 5.432919007533736\n",
      "Mini-batch 803 loss: 3.401343281052382\n",
      "Mini-batch 804 loss: 0.4219321912539724\n",
      "Mini-batch 805 loss: 1.9283493154288898\n",
      "Mini-batch 806 loss: 3.3316161211812676\n",
      "Mini-batch 807 loss: 4.576747970294462\n",
      "Mini-batch 808 loss: 0.3373572318145745\n",
      "Mini-batch 809 loss: 0.6487028926403187\n",
      "Mini-batch 810 loss: 4.945941745310238\n",
      "Mini-batch 811 loss: 0.2187761589249272\n",
      "Mini-batch 812 loss: 6.452247154131035\n",
      "num_correct: 24\n",
      "Mini-batch 813 loss: 2.812578285851942\n",
      "Mini-batch 814 loss: 1.495763724428285\n",
      "Mini-batch 815 loss: 1.5095387068668813\n",
      "Mini-batch 816 loss: 0.3542023772540972\n",
      "Mini-batch 817 loss: 0.7861900992746823\n",
      "Mini-batch 818 loss: 5.2993051357514345\n",
      "Mini-batch 819 loss: 1.1656990331208181\n",
      "Mini-batch 820 loss: 1.019788102572558\n",
      "Mini-batch 821 loss: 7.857106653710581\n",
      "Mini-batch 822 loss: 1.5948690037497832\n",
      "Mini-batch 823 loss: 0.461854940291954\n",
      "Mini-batch 824 loss: 0.24058446269533865\n",
      "Mini-batch 825 loss: 0.12744219413774177\n",
      "num_correct: 28\n",
      "Mini-batch 826 loss: 0.7997081123199475\n",
      "Mini-batch 827 loss: 0.7319681053585759\n",
      "Mini-batch 828 loss: 0.4575759734957286\n",
      "Mini-batch 829 loss: 0.7658399509685379\n",
      "Mini-batch 830 loss: 0.49814532989344673\n",
      "Mini-batch 831 loss: 2.4803414066865153\n",
      "Mini-batch 832 loss: 1.4603502724270527\n",
      "Mini-batch 833 loss: 0.7503443722474001\n",
      "Mini-batch 834 loss: 4.313460664306489\n",
      "Mini-batch 835 loss: 0.19115982846030244\n",
      "Mini-batch 836 loss: 1.1749353581424113\n",
      "Mini-batch 837 loss: 6.9203021687948985\n",
      "num_correct: 26\n",
      "Mini-batch 838 loss: 9.788640357230626\n",
      "Mini-batch 839 loss: 10.226153051602674\n",
      "Mini-batch 840 loss: 0.8876235506829231\n",
      "Mini-batch 841 loss: 7.332292240986104\n",
      "Mini-batch 842 loss: 1.4387069544546218\n",
      "Mini-batch 843 loss: 4.297415783125794\n",
      "Mini-batch 844 loss: 3.283138267356846\n",
      "Mini-batch 845 loss: 1.4047953442868906\n",
      "Mini-batch 846 loss: 1.7106025051582423\n",
      "Mini-batch 847 loss: 5.296934057836849\n",
      "Mini-batch 848 loss: 0.86392398391574\n",
      "Mini-batch 849 loss: 2.97394551907183\n",
      "Mini-batch 850 loss: 1.838919240625756\n",
      "num_correct: 29\n",
      "Mini-batch 851 loss: 1.4301614464755106\n",
      "Mini-batch 852 loss: 3.600546179120651\n",
      "Mini-batch 853 loss: 0.5129125909121949\n",
      "Mini-batch 854 loss: 1.0682690220206592\n",
      "Mini-batch 855 loss: 5.528068413483574\n",
      "Mini-batch 856 loss: 7.95449298719105\n",
      "Mini-batch 857 loss: 5.960970219796288\n",
      "Mini-batch 858 loss: 2.365142255681537\n",
      "Mini-batch 859 loss: 4.6280997001931095\n",
      "Mini-batch 860 loss: 0.5020347909935902\n",
      "Mini-batch 861 loss: 1.5281918345853711\n",
      "Mini-batch 862 loss: 3.6406114925541577\n",
      "num_correct: 30\n",
      "Mini-batch 863 loss: 0.972451820994118\n",
      "Mini-batch 864 loss: 1.1410362450037708\n",
      "Mini-batch 865 loss: 3.4078010349237133\n",
      "Mini-batch 866 loss: 1.4298899257584192\n",
      "Mini-batch 867 loss: 3.5090339583327212\n",
      "Mini-batch 868 loss: 6.449786470039\n",
      "Mini-batch 869 loss: 2.494813762302352\n",
      "Mini-batch 870 loss: 1.1248204231596737\n",
      "Mini-batch 871 loss: 1.6510900444304668\n",
      "Mini-batch 872 loss: 0.5623059938613515\n",
      "Mini-batch 873 loss: 0.2562028734853523\n",
      "Mini-batch 874 loss: 1.0445084875637456\n",
      "Mini-batch 875 loss: 0.27257810232476726\n",
      "num_correct: 27\n",
      "Saving state after 7000 iterations. Completed 88% of test set\n",
      "Mini-batch 876 loss: 1.6124142845191707\n",
      "Mini-batch 877 loss: 0.1818839723102179\n",
      "Mini-batch 878 loss: 1.8187713849609317\n",
      "Mini-batch 879 loss: 0.16551189468389968\n",
      "Mini-batch 880 loss: 2.0565480694885623\n",
      "Mini-batch 881 loss: 2.5242559265924687\n",
      "Mini-batch 882 loss: 2.802040926301697\n",
      "Mini-batch 883 loss: 1.2851244137015398\n",
      "Mini-batch 884 loss: 3.7284108412852115\n",
      "Mini-batch 885 loss: 1.4946826842890446\n",
      "Mini-batch 886 loss: 1.1317061455812254\n",
      "Mini-batch 887 loss: 4.072672246016359\n",
      "num_correct: 29\n",
      "Mini-batch 888 loss: 3.2589974833012016\n",
      "Mini-batch 889 loss: 1.1230846270653068\n",
      "Mini-batch 890 loss: 1.1197470144249717\n",
      "Mini-batch 891 loss: 2.404057264630953\n",
      "Mini-batch 892 loss: 1.9908259303909988\n",
      "Mini-batch 893 loss: 0.13028775319034844\n",
      "Mini-batch 894 loss: 4.801755851039297\n",
      "Mini-batch 895 loss: 3.983496662135233\n",
      "Mini-batch 896 loss: 0.9378337177746331\n",
      "Mini-batch 897 loss: 1.1627610774696966\n",
      "Mini-batch 898 loss: 0.8353716993544247\n",
      "Mini-batch 899 loss: 0.30958379787122003\n",
      "Mini-batch 900 loss: 1.1989583711442913\n",
      "num_correct: 27\n",
      "Mini-batch 901 loss: 1.646686881326051\n",
      "Mini-batch 902 loss: 5.269502655602755\n",
      "Mini-batch 903 loss: 0.6371113680738104\n",
      "Mini-batch 904 loss: 3.41977622514116\n",
      "Mini-batch 905 loss: 0.09452808114494837\n",
      "Mini-batch 906 loss: 1.4441856065486742\n",
      "Mini-batch 907 loss: 1.5091949766035588\n",
      "Mini-batch 908 loss: 0.7921006804922658\n",
      "Mini-batch 909 loss: 9.88863450879\n",
      "Mini-batch 910 loss: 7.805627261850228\n",
      "Mini-batch 911 loss: 8.606832649518408\n",
      "Mini-batch 912 loss: 0.2540225441857608\n",
      "num_correct: 28\n",
      "Mini-batch 913 loss: 0.27152108856058266\n",
      "Mini-batch 914 loss: 13.282821580669316\n",
      "Mini-batch 915 loss: 6.678803986042734\n",
      "Mini-batch 916 loss: 0.39365978307482685\n",
      "Mini-batch 917 loss: 2.808439410825306\n",
      "Mini-batch 918 loss: 1.3858984759012614\n",
      "Mini-batch 919 loss: 4.298392882351539\n",
      "Mini-batch 920 loss: 0.246180957434452\n",
      "Mini-batch 921 loss: 4.919121123031285\n",
      "Mini-batch 922 loss: 3.4577760516394496\n",
      "Mini-batch 923 loss: 0.6094839942997935\n",
      "Mini-batch 924 loss: 1.123876658424762\n",
      "Mini-batch 925 loss: 1.2856715210690997\n",
      "num_correct: 27\n",
      "Mini-batch 926 loss: 2.103649312111872\n",
      "Mini-batch 927 loss: 2.885827724823202\n",
      "Mini-batch 928 loss: 0.3293269249373954\n",
      "Mini-batch 929 loss: 4.252624697462474\n",
      "Mini-batch 930 loss: 2.578291143838716\n",
      "Mini-batch 931 loss: 2.2627949374124636\n",
      "Mini-batch 932 loss: 1.6944240180882337\n",
      "Mini-batch 933 loss: 0.8635916790224475\n",
      "Mini-batch 934 loss: 1.6497315788684088\n",
      "Mini-batch 935 loss: 1.649127536601402\n",
      "Mini-batch 936 loss: 1.090735828823086\n",
      "Mini-batch 937 loss: 0.4000127672048222\n",
      "num_correct: 27\n",
      "Mini-batch 938 loss: 6.1886864556261125\n",
      "Mini-batch 939 loss: 0.3329129500005305\n",
      "Mini-batch 940 loss: 1.4153405010080458\n",
      "Mini-batch 941 loss: 4.625058454761412\n",
      "Mini-batch 942 loss: 2.8056416988445316\n",
      "Mini-batch 943 loss: 1.2996278024989627\n",
      "Mini-batch 944 loss: 0.24639883658919007\n",
      "Mini-batch 945 loss: 8.07893514641756\n",
      "Mini-batch 946 loss: 7.16271713550265\n",
      "Mini-batch 947 loss: 3.1664281527038685\n",
      "Mini-batch 948 loss: 2.0106474441187183\n",
      "Mini-batch 949 loss: 0.24404878446610276\n",
      "Mini-batch 950 loss: 3.708497360871787\n",
      "num_correct: 28\n",
      "Mini-batch 951 loss: 1.1429641726430104\n",
      "Mini-batch 952 loss: 4.157940037384162\n",
      "Mini-batch 953 loss: 0.34958036225563194\n",
      "Mini-batch 954 loss: 0.5463360195468048\n",
      "Mini-batch 955 loss: 2.4955744292992894\n",
      "Mini-batch 956 loss: 0.7063995602406115\n",
      "Mini-batch 957 loss: 0.41907403065633975\n",
      "Mini-batch 958 loss: 5.273819126299705\n",
      "Mini-batch 959 loss: 6.245248573987239\n",
      "Mini-batch 960 loss: 3.6755821988302637\n",
      "Mini-batch 961 loss: 6.805288752189739\n",
      "Mini-batch 962 loss: 3.0729314753330748\n",
      "num_correct: 27\n",
      "Mini-batch 963 loss: 1.0050742159352022\n",
      "Mini-batch 964 loss: 3.3479838289221355\n",
      "Mini-batch 965 loss: 2.993983832963722\n",
      "Mini-batch 966 loss: 0.3105514341881179\n",
      "Mini-batch 967 loss: 1.849472938290374\n",
      "Mini-batch 968 loss: 0.22634177539345984\n",
      "Mini-batch 969 loss: 1.4071409302746345\n",
      "Mini-batch 970 loss: 1.1919106385826364\n",
      "Mini-batch 971 loss: 2.305672289680593\n",
      "Mini-batch 972 loss: 4.768107517565603\n",
      "Mini-batch 973 loss: 2.4156397523775732\n",
      "Mini-batch 974 loss: 4.534015304497631\n",
      "Mini-batch 975 loss: 0.1817265716833859\n",
      "num_correct: 26\n",
      "Mini-batch 976 loss: 0.3620316147156559\n",
      "Mini-batch 977 loss: 0.19266592598212318\n",
      "Mini-batch 978 loss: 1.2382550949348505\n",
      "Mini-batch 979 loss: 1.5676725326315955\n",
      "Mini-batch 980 loss: 2.448881016761898\n",
      "Mini-batch 981 loss: 1.2104132383589659\n",
      "Mini-batch 982 loss: 2.585067377640593\n",
      "Mini-batch 983 loss: 1.901141392648783\n",
      "Mini-batch 984 loss: 1.3085135918232729\n",
      "Mini-batch 985 loss: 1.2019767984202552\n",
      "Mini-batch 986 loss: 1.5870138255852573\n",
      "Mini-batch 987 loss: 3.1678859216777937\n",
      "num_correct: 24\n",
      "Mini-batch 988 loss: 3.6993079641896083\n",
      "Mini-batch 989 loss: 2.3646047703831523\n",
      "Mini-batch 990 loss: 2.9682036508232326\n",
      "Mini-batch 991 loss: 0.48332176685405537\n",
      "Mini-batch 992 loss: 0.3625216872970175\n",
      "Mini-batch 993 loss: 1.3110857074023998\n",
      "Mini-batch 994 loss: 1.8951331123606332\n",
      "Mini-batch 995 loss: 5.332519496202126\n",
      "Mini-batch 996 loss: 4.479462578564113\n",
      "Mini-batch 997 loss: 1.7901796520554902\n",
      "Mini-batch 998 loss: 0.31270342714506877\n",
      "Mini-batch 999 loss: 1.2441937087983053\n",
      "Mini-batch 1000 loss: 0.0754720141314892\n",
      "num_correct: 27\n",
      "Saving state after 8000 iterations. Completed 100% of test set\n",
      "Finished training in 3830.8739471435547\n"
     ]
    }
   ],
   "source": [
    "# Train set loop\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses = []\n",
    "evaluations = []\n",
    "loss = 0\n",
    "for i, (image, label) in enumerate(zip(dataset.train_images, dataset.train_labels)):\n",
    "    i += 1 \n",
    "\n",
    "    # forward and backward pass\n",
    "    target = encoder(label)\n",
    "    pred = cnn.forward(image)\n",
    "    loss += cnn.backward(target)\n",
    "\n",
    "    # gradient updates every BATCH_SIZE iterations\n",
    "    if i % BATCH_SIZE == 0: \n",
    "        cnn.update()\n",
    "        print(f\"Mini-batch {i//8} loss: {loss}\")\n",
    "        losses.append(loss)\n",
    "        loss = 0\n",
    "\n",
    "    # evaluate every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        cnn.training = False\n",
    "        num_correct = 0\n",
    "        for _ in range(30): \n",
    "            index = np.random.randint(len(dataset.test_images))\n",
    "            image = dataset.test_images[index]\n",
    "            label = dataset.test_labels[index]\n",
    "            target = encoder(label)\n",
    "            pred = cnn.forward(image)\n",
    "\n",
    "            if np.argmax(pred) == label:\n",
    "                num_correct += 1\n",
    "        cnn.clear_gradients()\n",
    "        print(f\"num_correct: {num_correct}\")\n",
    "        evaluations.append(num_correct)\n",
    "        cnn.training = True\n",
    "\n",
    "    # save state every 1000 iterations\n",
    "    if i % 1000 == 0: \n",
    "        print(f\"Saving state after {i} iterations. Completed {i / len(dataset.train_images) * 100:.0f}% of test set\")\n",
    "        cnn.save_state()\n",
    "        \n",
    "end = time.time()\n",
    "print(\"Finished training in\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 90.55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Test set loop\n",
    "num_correct = 0\n",
    "for image, label in zip(dataset.test_images, dataset.test_labels):\n",
    "    target = encoder(label)\n",
    "\n",
    "    pred = cnn.forward(image)\n",
    "    if np.argmax(pred) == label:\n",
    "        num_correct += 1\n",
    "\n",
    "print(\"Accuracy =\", num_correct / len(dataset.test_labels) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
